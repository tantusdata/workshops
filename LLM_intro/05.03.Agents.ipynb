{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Agent with Json action format\n",
    "\n",
    "We have learned how agents works and how to build them in LangChain from scratch.\n",
    "\n",
    "But in practise, what you want to do is to take full advantage of the framework and build your own agent with the least effort.\n",
    "This is the excerise we are going to do in this section.\n",
    "\n",
    "We will take a prompt from langchain hub which asks the model to output action in json format.\n",
    "\n",
    "You task is to connect the components into a working agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Prompt\n",
    "\n",
    "We will use one of popular prompt available on langchain hub `hwchase17/react-multi-input-json`\n",
    "\n",
    "It consist of two messages:\n",
    "- system one, which descripes the how the agent should response and available prompts\n",
    "- human message which will contain current input and gent scratchpad with previously executed actions and their results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['tool_names', 'tools'], template='Respond to the human as helpfully and accurately as possible. You have access to the following tools:\\n\\n{tools}\\n\\nUse a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\\n\\nValid \"action\" values: \"Final Answer\" or {tool_names}\\n\\nProvide only ONE action per $JSON_BLOB, as shown:\\n\\n```\\n{{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}}\\n```\\n\\nFollow this format:\\n\\nQuestion: input question to answer\\nThought: consider previous and subsequent steps\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: action result\\n... (repeat Thought/Action/Observation N times)\\nThought: I know what to respond\\nAction:\\n```\\n{{\\n  \"action\": \"Final Answer\",\\n  \"action_input\": \"Final response to human\"\\n}}\\n\\nBegin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation')),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['agent_scratchpad', 'input'], template='{input}\\n\\n{agent_scratchpad}\\n (reminder to respond in a JSON blob no matter what)'))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = hub.pull(\"hwchase17/react-multi-input-json\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input variables: f['tool_names', 'tools']\n",
      "Prompt:\n",
      "Respond to the human as helpfully and accurately as possible. You have access to the following tools:\n",
      "\n",
      "{tools}\n",
      "\n",
      "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
      "\n",
      "Valid \"action\" values: \"Final Answer\" or {tool_names}\n",
      "\n",
      "Provide only ONE action per $JSON_BLOB, as shown:\n",
      "\n",
      "```\n",
      "{{\n",
      "  \"action\": $TOOL_NAME,\n",
      "  \"action_input\": $INPUT\n",
      "}}\n",
      "```\n",
      "\n",
      "Follow this format:\n",
      "\n",
      "Question: input question to answer\n",
      "Thought: consider previous and subsequent steps\n",
      "Action:\n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "Observation: action result\n",
      "... (repeat Thought/Action/Observation N times)\n",
      "Thought: I know what to respond\n",
      "Action:\n",
      "```\n",
      "{{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Final response to human\"\n",
      "}}\n",
      "\n",
      "Begin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation\n",
      "\n",
      " ==================================================\n",
      "\n",
      "Input variables: f['agent_scratchpad', 'input']\n",
      "Prompt:\n",
      "{input}\n",
      "\n",
      "{agent_scratchpad}\n",
      " (reminder to respond in a JSON blob no matter what)\n",
      "\n",
      " ==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"hwchase17/react-multi-input-json\")\n",
    "\n",
    "for message in prompt.messages:\n",
    "    print(f\"Input variables: f{message.prompt.input_variables}\")\n",
    "    print(f\"Prompt:\\n{message.prompt.template}\")\n",
    "    print(\"\\n \" + \"=\"* 50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools\n",
    "\n",
    "Here you can define the tools you want to use in your agent.\n",
    "\n",
    "If environment variables for Serep and Wolfram are set, we will automatically add those tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import GoogleSerperAPIWrapper, DuckDuckGoSearchAPIWrapper, WolframAlphaAPIWrapper\n",
    "from langchain.tools import Tool\n",
    "\n",
    "tools = [\n",
    "\n",
    "]\n",
    "\n",
    "if os.getenv(\"SERPER_API_KEY\") is None:\n",
    "    print(\"Serper Api Key not set!\")\n",
    "else:\n",
    "    tools.append(Tool(\n",
    "        name=\"web_search\",\n",
    "        func=GoogleSerperAPIWrapper().run,\n",
    "        description=\"Usefull if you need to find out some additional information. You should ask targeted questions.\"\n",
    "    ),)\n",
    "if os.getenv(\"WOLFRAM_ALPHA_APPID\") is None:\n",
    "    print(\"Wolfram Alpha App ID not set!\")\n",
    "else:\n",
    "    tools.append(Tool(\n",
    "        name=\"calculator\", \n",
    "        func=WolframAlphaAPIWrapper().run,\n",
    "        description=\"Calculator. Use it for any calculation. Input should be a string with equation.\"\n",
    "    ),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Agent chain\n",
    "\n",
    "Here we will test your understanding of LangChain building blocks and how Agents work.\n",
    "\n",
    "Steps which you need to do:\n",
    "- create `prompt_formatted`, check the system prompt and what input variables it has. Tools will be the same at each step, so you can either build chain which always format the prompt with them or use prompt function `.partial` which will partially format it\n",
    "- create `llm_with_stop`, recall from the previous notebook, that we want to stop LLM from generating new tokens when it outputs observation step to execute the action and provide its results as observation\n",
    "- create `agent` which will\n",
    "    - take current input consisting of `input` and `intermediate_steps` and passes the input and somehow created `agent_scratchpad` to the prompt\n",
    "    - formats the prompt with current `input` and `agent_scratchpad`\n",
    "    - calls `llm_with_stop` to produce output\n",
    "    - extracts the structured output in JSON using `JSONAgentOutputParser`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "from langchain.tools.render import render_text_description_and_args # Render the tool name, description, and args in plain text.\n",
    "from langchain.agents.format_scratchpad import format_log_to_str # Construct the scratchpad that lets the agent continue its thought process.\n",
    "from langchain.agents.output_parsers import JSONAgentOutputParser # Parses tool invocations and final answers in JSON format.\n",
    "\n",
    "prompt_formatted = prompt.partial(\n",
    "    tools=render_text_description_and_args(tools),\n",
    "    tool_names=\", \".join([t.name for t in tools]),\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0613\", temperature=0)\n",
    "llm_with_stop = llm.bind(stop=[\"Observation\"])\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_log_to_str(x[\"intermediate_steps\"]),\n",
    "    }\n",
    "    | prompt_formatted\n",
    "    | llm_with_stop\n",
    "    | JSONAgentOutputParser()\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, max_steps=3, verbose=True, handle_parsing_errors=True) # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find the current price of Tesla stocks.\n",
      "\n",
      "Action:\n",
      "```{\n",
      "  \"action\": \"web_search\",\n",
      "  \"action_input\": \"current price of Tesla stocks\"\n",
      "}```\u001b[0m\u001b[36;1m\u001b[1;3m234.30 +0.71 (0.30%)\u001b[0m\u001b[32;1m\u001b[1;3mAction:\n",
      "```{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The current price of 123 Tesla stocks is $234.30 per share.\"\n",
      "}```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke(\n",
    "    {\"input\": \"What is the price of 123 Tesla stocks?\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current price of 123 Tesla stocks is $234.30 per share.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['output']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "from langchain.tools.render import render_text_description_and_args # Render the tool name, description, and args in plain text.\n",
    "from langchain.agents.format_scratchpad import format_log_to_str # Construct the scratchpad that lets the agent continue its thought process.\n",
    "from langchain.agents.output_parsers import JSONAgentOutputParser # Parses tool invocations and final answers in JSON format.\n",
    "\n",
    "prompt_formatted = prompt.partial(\n",
    "    tools=render_text_description_and_args(tools),\n",
    "    tool_names=\", \".join([t.name for t in tools]),\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0613\", temperature=0)\n",
    "llm_with_stop = llm.bind(stop=[\"Observation\"])\n",
    "\n",
    "agent = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: format_log_to_str(x[\"intermediate_steps\"]),\n",
    "    }\n",
    "    | prompt_formatted\n",
    "    | llm_with_stop\n",
    "    | JSONAgentOutputParser()\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, max_steps=3, verbose=True, handle_parsing_errors=True) # type: ignore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
