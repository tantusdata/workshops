{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "189bb6f6-6373-44fb-9e6e-08252bdd34e6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Cross Join\n",
    "Cross join is always an expensive operation, mostly due to the amount of data it produces. However even even here there are ways to do it efficiently and ways to keep waiting long hours for a job to complete. In this notebook we will look at a job that computes cross-join of orders, grouped by order ID. We want to produce all product pairs per every order available.\n",
    "\n",
    "## The goal\n",
    "The current (naive) implementation takes over 1 hour to compute all the pairs - you can verify this by running the current implementation. Browse through the data and see what is causing the problem, then try to correct this. A really optimized solution may take as little as 10 minutes instead of 2 hours. You are welcome to experiment and try any of your ideas. However, if you need an inspiration, try going in this plan:\n",
    "1. Salt one side of the join, add a salt value to every row.\n",
    "2. Salt the other side, this time do a cross join with every possible salt value.\n",
    "3. On the output, fix the projection to not leak implementation details (added columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d5bcd81-4007-4b44-9125-74fb60b785f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "INPUT_PATH = \"/Volumes/tantusdata_playground/default/bde-2023/input/orders.parquet/\"\n",
    "\n",
    "# Volume path - make sure you have created a volume for yourself.\n",
    "VOLUME_PATH = \"/Volumes/tantusdata_playground/default/test-user-001\"\n",
    "\n",
    "WRITE_PATH = f\"{VOLUME_PATH}/03-cross-join/orders-pairs.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "70e50890-a9d8-42f1-8962-202d63099210",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "orders = spark.read.parquet(INPUT_PATH)\n",
    "\n",
    "orders_lhs = orders.select(\n",
    "    F.col(\"orderID1\"), \n",
    "    F.col(\"productID\").alias(f\"productID1\")\n",
    ")\n",
    "\n",
    "orders_rhs = orders.select(\n",
    "    F.col(\"orderID2\"), \n",
    "    F.col(\"productID\").alias(f\"productID1\")\n",
    ")\n",
    "\n",
    "# FixMe: try to optimize this join. Make sure to check the data being processed by this job.\n",
    "\n",
    "orders_pairs = (orders_lhs\n",
    "    .join(orders_rhs, F.col(\"orderID1\") == F.col(\"orderID2\")) & (F.col(\"productID1\") < F.col(\"productID2\"))\n",
    ")\n",
    "\n",
    "orders_pairs.write.parquet(WRITE_PATH)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03-cross-join",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
